{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e270ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, AutoModel\n",
    "import torch\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87adf9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4254f4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for p in model.parameters():\n",
    "    i+=1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18090049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(50257, 768)\n",
      "Embedding(1024, 768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "ModuleList(\n",
      "  (0-11): 12 x GPT2Block(\n",
      "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): GPT2Attention(\n",
      "      (c_attn): Conv1D(nf=2304, nx=768)\n",
      "      (c_proj): Conv1D(nf=768, nx=768)\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): GPT2MLP(\n",
      "      (c_fc): Conv1D(nf=3072, nx=768)\n",
      "      (c_proj): Conv1D(nf=768, nx=3072)\n",
      "      (act): NewGELUActivation()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.children():\n",
    "    print(parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c45d984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0640, -0.0756, -0.0386,  0.0328,  0.0758,  0.0314,  0.0379,  0.0301,\n",
      "         0.1517, -0.0924, -0.0618,  0.1648, -0.1104, -0.0405,  0.0668,  0.0766,\n",
      "         0.0952,  0.1393,  0.0134,  0.2077], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0640, -0.0756, -0.0386,  0.0328,  0.0758,  0.0314,  0.0379,  0.0301,\n",
      "         0.1517, -0.0924, -0.0618,  0.1648, -0.1104, -0.0405,  0.0668,  0.0766,\n",
      "         0.0952,  0.1393,  0.0134,  0.2077], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "lstm_layer = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "# (batch_size, seq_len, input_size)\n",
    "input_seq = torch.randn(3, 5, 10)\n",
    "# 初始隐藏状态和细胞状态 (num_layers, batch_size, hidden_size)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output_seq, (hn, cn) = lstm_layer(input_seq, (h0, c0))\n",
    "print(output_seq[0, -1]) # torch.Size([3, 5, 20])\n",
    "print(hn[1, 0])         # torch.Size([2, 3, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd1c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=8, collate_fn=dataset.collate_fn)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65937c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = next(iter(poem_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083d6699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 5774, 7883, 7392, 3717, 1582, 8024, 3731, 7716, 6852, 7599, 1674,\n",
       "         511, 5303, 3189, 7390, 2519,  100, 8024,  862, 3198, 5387, 7961,  100,\n",
       "         511,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['token_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "715bee75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]欲说昭君歛翠蛾，清声委曲怨于歌。谁家年少春风里，拋与金钱唱好多。[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tokenizer.convert_ids_to_tokens(t['token_ids'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f306685",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [str(item)[5:] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09a6929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/clear_data.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4f034bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'度门能不访，冒雪屡西东。已想人如玉，遥怜马似骢。乍迷金谷路，稍变上阳宫。还比相思意，纷纷正满空。'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4852b515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 101, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('[CLS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "363bdba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]度门能不访，冒雪屡西东。已想人如玉，遥怜马似骢。乍迷金谷路，稍变上阳宫。还比相思意，纷纷正满空。'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4915b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8902650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e0c982c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "830cd174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('<|endoftext|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "429e67d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '<', '|', 'end', '##of', '##text', '|', '>', '[SEP]']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer('<|endoftext|>')['input_ids'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis-lmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
